#!/bin/zsh
# =============================================================================
# ComfyUI Startup Script - Optimized for RTX 5090 (Blackwell)
# =============================================================================

echo "üöÄ ComfyUI RTX 5090 Optimized Startup"
echo "====================================================="

# -----------------------------------------------------------------------------
# Environment Token Verification
# -----------------------------------------------------------------------------
echo "üîë Checking API tokens..."
echo "   GitHub Token (GH_TOKEN): $( [ -n "$GH_TOKEN" ] && echo "SET ‚úì" || echo "NOT SET" )"
echo "   Hugging Face Token: $( [ -n "$HUGGING_FACE_HUB_TOKEN" ] && echo "SET ‚úì" || echo "NOT SET" )"
echo "   Civitai API Key: $( [ -n "$CIVITAI_API_KEY" ] && echo "SET ‚úì" || echo "NOT SET" )"
echo "-----------------------------------------------------"

# -----------------------------------------------------------------------------
# RTX 5090 / Blackwell Performance Optimizations
# -----------------------------------------------------------------------------
echo "‚ö° Applying RTX 5090 (Blackwell) optimizations..."

# CUDA optimizations
export CUDA_MODULE_LOADING=LAZY
export NVIDIA_TF32_OVERRIDE=1
export CUDA_DEVICE_ORDER=PCI_BUS_ID

# PyTorch memory optimization
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# cuDNN autotune for optimal kernel selection
export TORCH_CUDNN_BENCHMARK=1
export TORCH_CUDNN_BENCHMARK_LIMIT=10

# Thread optimization for AMD Ryzen 7 7700 (16 threads)
export TORCH_NUM_THREADS=16
export OMP_NUM_THREADS=16
export MKL_NUM_THREADS=16
export OPENBLAS_NUM_THREADS=16

# Triton cache on fast storage
export TRITON_CACHE_DIR=/tmp/triton_cache
mkdir -p /tmp/triton_cache

echo "   ‚úì CUDA_MODULE_LOADING=LAZY"
echo "   ‚úì NVIDIA_TF32_OVERRIDE=1"
echo "   ‚úì PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
echo "   ‚úì TORCH_CUDNN_BENCHMARK=1"
echo "   ‚úì Thread count: 16"
echo "-----------------------------------------------------"

# -----------------------------------------------------------------------------
# Virtual Environment Setup
# -----------------------------------------------------------------------------
VENV_PYTHON="/opt/comf/.venv/bin/python3"
VENV_ACTIVATE="/opt/comf/.venv/bin/activate"
FROZEN_REQUIREMENTS_PATH="/opt/comf/requirements_frozen.txt"

echo "üì¶ Verifying Python virtual environment..."

# Activate venv and verify pip
source "$VENV_ACTIVATE"
if ! python -m pip --version > /dev/null 2>&1; then
    echo "‚ö†Ô∏è  pip not found, attempting to ensure it..."
    python -m ensurepip || { echo "‚ùå Failed to ensure pip. Exiting."; exit 1; }
fi

# Upgrade pip silently
python -m pip install --upgrade pip setuptools wheel > /dev/null 2>&1 || true

# -----------------------------------------------------------------------------
# Package Verification
# -----------------------------------------------------------------------------
echo "üîç Verifying critical packages..."

# Check torch
if python -c "import torch" > /dev/null 2>&1; then
    TORCH_VERSION=$(python -c "import torch; print(torch.__version__)")
    CUDA_AVAILABLE=$(python -c "import torch; print(torch.cuda.is_available())")
    echo "   ‚úì PyTorch: $TORCH_VERSION (CUDA: $CUDA_AVAILABLE)"
else
    echo "   ‚ùå PyTorch not found!"
fi

# Check SageAttention
if python -c "import sageattention" > /dev/null 2>&1; then
    echo "   ‚úì SageAttention: OK"
else
    echo "   ‚ö†Ô∏è  SageAttention not available (will use fallback)"
fi

# Check TensorRT (Blackwell requires 10.7+)
if python -c "import tensorrt" > /dev/null 2>&1; then
    TRT_VERSION=$(python -c "import tensorrt; print(tensorrt.__version__)")
    TRT_MAJOR=$(echo "$TRT_VERSION" | cut -d. -f1)
    TRT_MINOR=$(echo "$TRT_VERSION" | cut -d. -f2)
    if [ "$TRT_MAJOR" -ge 10 ] && [ "$TRT_MINOR" -ge 7 ]; then
        echo "   ‚úì TensorRT: $TRT_VERSION (Blackwell compatible)"
    else
        echo "   ‚ö†Ô∏è  TensorRT: $TRT_VERSION (Blackwell requires 10.7+)"
    fi
else
    echo "   ‚ö†Ô∏è  TensorRT not available"
fi

# Check other critical packages
python -c "import aiohttp; print(f'   ‚úì aiohttp: {aiohttp.__version__}')" 2>/dev/null || echo "   ‚ö†Ô∏è  aiohttp not available"
python -c "import numpy; print(f'   ‚úì numpy: {numpy.__version__}')" 2>/dev/null || echo "   ‚ö†Ô∏è  numpy not available"
python -c "import transformers; print(f'   ‚úì transformers: {transformers.__version__}')" 2>/dev/null || echo "   ‚ö†Ô∏è  transformers not available"

echo "-----------------------------------------------------"

# -----------------------------------------------------------------------------
# GPU Information and Architecture Verification
# -----------------------------------------------------------------------------
echo "üñ•Ô∏è  GPU Information:"
if command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv,noheader 2>/dev/null | while read line; do
        echo "   $line"
    done

    # Verify Blackwell architecture (sm_120)
    GPU_ARCH=$(python -c "import torch; print(torch.cuda.get_device_capability()[0] * 10 + torch.cuda.get_device_capability()[1])" 2>/dev/null || echo "unknown")
    if [ "$GPU_ARCH" = "120" ]; then
        echo "   ‚úì GPU Architecture: sm_120 (Blackwell) - Optimizations enabled"
    elif [ "$GPU_ARCH" != "unknown" ]; then
        echo "   ‚ÑπÔ∏è  GPU Architecture: sm_$GPU_ARCH (Expected sm_120 for RTX 5090)"
    fi
else
    echo "   nvidia-smi not available"
fi
echo "-----------------------------------------------------"

# -----------------------------------------------------------------------------
# Launch ComfyUI with RTX 5090 Optimizations
# -----------------------------------------------------------------------------
echo "‚ú® Launching ComfyUI with Blackwell optimizations..."
echo ""
echo "   Flags:"
echo "   --use-sage-attention   (2-3x attention speedup)"
echo "   --fp8-unet --fp8-te    (FP8 on Blackwell Tensor Cores)"
echo "   --fast fp16_accumulation (15-25% matmul boost)"
echo "   --highvram             (keep models in 32GB VRAM)"
echo "   --reserve-vram 2       (reserve 2GB for OS)"
echo "   --preview-method taesd (fast previews)"
echo ""
echo "====================================================="

cd /opt/comf

$VENV_PYTHON main.py \
    --listen \
    --port 8188 \
    --enable-cors-header \
    --use-sage-attention \
    --fp8-unet \
    --fp8-te \
    --fast fp16_accumulation \
    --highvram \
    --reserve-vram 2 \
    --preview-method taesd \
    --extra-model-paths-config /opt/comf/extra_model_paths.yaml \
    --output-directory /mnt/output_host

# -----------------------------------------------------------------------------
# Fallback Shell
# -----------------------------------------------------------------------------
echo ""
echo "====================================================="
echo "ComfyUI process has finished or was stopped."
echo ""
echo "To restart manually:"
echo "  $VENV_PYTHON main.py --listen --port 8188 --enable-cors-header --use-sage-attention --fp8-unet --fp8-te --fast fp16_accumulation --highvram"
echo ""
echo "Type 'exit' to close (this will stop the container)."
echo "====================================================="

exec /bin/zsh
